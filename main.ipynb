{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l-Wc3MXrzoXw",
    "outputId": "c0f39647-9b80-4a3b-8d6d-efe5a49e7837"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\nenug\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: python-docx in c:\\users\\nenug\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\nenug\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\nenug\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-docx) (5.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\nenug\\appdata\\roaming\\python\\python311\\site-packages (from python-docx) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\nenug\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nenug\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nenug\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nenug\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nenug\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2 python-docx pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6lpw95Dw5H-a",
    "outputId": "8ca6b85b-bd2e-4d63-e401-d2abf4e3700f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo 'dataset_texto_normalizado.csv' creado con éxito.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader\n",
    "from docx import Document\n",
    "\n",
    "# Ruta de la carpeta que contiene los archivos\n",
    "folder_path = \"curriculum_vitae_data-master\\word\"\n",
    "\n",
    "# Función para extraer texto de archivos PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        reader = PdfReader(pdf_path)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Error al leer el PDF: {e}\"\n",
    "\n",
    "# Función para extraer texto de archivos Word\n",
    "def extract_text_from_word(doc_path):\n",
    "    try:\n",
    "        doc = Document(doc_path)\n",
    "        text = \"\\n\".join([paragraph.text for paragraph in doc.paragraphs])\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Error al leer el Word: {e}\"\n",
    "\n",
    "# Función para normalizar texto\n",
    "def normalize_text(text):\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    # Eliminar caracteres especiales y dejar solo letras, números y espacios\n",
    "    text = re.sub(r\"[^a-záéíóúüñ0-9\\s]\", \"\", text)\n",
    "    # Eliminar espacios extra\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "# Procesar los archivos y guardar en un dataset\n",
    "data = []\n",
    "for file_name in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    if file_name.endswith(\".pdf\"):\n",
    "        text = extract_text_from_pdf(file_path)\n",
    "        file_type = \"PDF\"\n",
    "    elif file_name.endswith(\".docx\"):\n",
    "        text = extract_text_from_word(file_path)\n",
    "        file_type = \"Word\"\n",
    "    else:\n",
    "        continue  # Ignorar archivos no compatibles\n",
    "\n",
    "    # Normalizar texto\n",
    "    normalized_text = normalize_text(text)\n",
    "\n",
    "    # Agregar los datos normalizados al dataset\n",
    "    data.append({\"File Name\": file_name, \"File Type\": file_type, \"Content\": normalized_text})\n",
    "\n",
    "# Guardar en un DataFrame y exportar a CSV\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"dataset_texto_normalizado.csv\", index=False)\n",
    "\n",
    "print(\"Archivo 'dataset_texto_normalizado.csv' creado con éxito.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1658
    },
    "id": "nEJ7aAw4728L",
    "outputId": "e6582854-ec22-4d2a-d51f-ac81d8f97e46"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>File Type</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.docx</td>\n",
       "      <td>Word</td>\n",
       "      <td>personal information curriculum vitae full nam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.docx</td>\n",
       "      <td>Word</td>\n",
       "      <td>resume abhishek magotra hno632 sector4 channi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.docx</td>\n",
       "      <td>Word</td>\n",
       "      <td>curriculum vitae ranjeet singh address g33 2nd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000.docx</td>\n",
       "      <td>Word</td>\n",
       "      <td>nihmathakangmailcom to satisfy my technologydr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001.docx</td>\n",
       "      <td>Word</td>\n",
       "      <td>syed abuthaheer n 2 years experience in hvac d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>995.docx</td>\n",
       "      <td>Word</td>\n",
       "      <td>curriculum vitae ssam george email sameee85yah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>996.docx</td>\n",
       "      <td>Word</td>\n",
       "      <td>curriculum vitae profile a qualified professio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>997.docx</td>\n",
       "      <td>Word</td>\n",
       "      <td>curriculum vitae work experience 7 stores bcc ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2294</th>\n",
       "      <td>998.docx</td>\n",
       "      <td>Word</td>\n",
       "      <td>curriculum vitae name chariharasudhan year of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>999.docx</td>\n",
       "      <td>Word</td>\n",
       "      <td>curriculum vitae b nizam 138 kasigarden 1st st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2296 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      File Name File Type                                            Content\n",
       "0        1.docx      Word  personal information curriculum vitae full nam...\n",
       "1       10.docx      Word  resume abhishek magotra hno632 sector4 channi ...\n",
       "2      100.docx      Word  curriculum vitae ranjeet singh address g33 2nd...\n",
       "3     1000.docx      Word  nihmathakangmailcom to satisfy my technologydr...\n",
       "4     1001.docx      Word  syed abuthaheer n 2 years experience in hvac d...\n",
       "...         ...       ...                                                ...\n",
       "2291   995.docx      Word  curriculum vitae ssam george email sameee85yah...\n",
       "2292   996.docx      Word  curriculum vitae profile a qualified professio...\n",
       "2293   997.docx      Word  curriculum vitae work experience 7 stores bcc ...\n",
       "2294   998.docx      Word  curriculum vitae name chariharasudhan year of ...\n",
       "2295   999.docx      Word  curriculum vitae b nizam 138 kasigarden 1st st...\n",
       "\n",
       "[2296 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Cargar pipeline de clasificación\u001b[39;00m\n\u001b[0;32m      4\u001b[0m classifier \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero-shot-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/bart-large-mnli\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Cargar pipeline de clasificación\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Lista de habilidades clave\n",
    "skills_list = [\n",
    "    \"Python\", \"Java\", \"Gestión de Proyectos\", \"SQL\", \"Machine Learning\",\n",
    "    \"Excel\", \"Análisis de Datos\", \"Desarrollo Web\", \"Javascript\"\n",
    "]\n",
    "\n",
    "# Función para clasificar habilidades en el texto\n",
    "def detect_skills_transformers(text):\n",
    "    result = classifier(text, skills_list, multi_label=True)\n",
    "    detected_skills = [\n",
    "        skill for skill, score in zip(result[\"labels\"], result[\"scores\"]) if score > 0.5\n",
    "    ]\n",
    "    return detected_skills\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etiquetas para clasificar el nivel de inglés\n",
    "english_levels = [\"básico\", \"intermedio\", \"avanzado\", \"bilingüe\"]\n",
    "\n",
    "# Función para clasificar nivel de inglés\n",
    "def detect_english_level_transformers(text):\n",
    "    result = classifier(text, english_levels, multi_label=False)\n",
    "    return result[\"labels\"][0]  # Devuelve la etiqueta más probable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "# Cargar modelo de NER\n",
    "ner_model = \"dbmdz/bert-large-cased-finetuned-conll03-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(ner_model)\n",
    "model = AutoModelForTokenClassification.from_pretrained(ner_model)\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Función para extraer información de NER\n",
    "def extract_entities(text):\n",
    "    ner_results = ner_pipeline(text)\n",
    "    age = \"No especificado\"\n",
    "    gender = \"No especificado\"\n",
    "    \n",
    "    for entity in ner_results:\n",
    "        if entity[\"entity\"] == \"AGE\":\n",
    "            age = entity[\"word\"]\n",
    "        elif entity[\"entity\"] in [\"MALE\", \"FEMALE\"]:\n",
    "            gender = \"Masculino\" if entity[\"entity\"] == \"MALE\" else \"Femenino\"\n",
    "    \n",
    "    return age, gender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed = []\n",
    "\n",
    "for record in data:\n",
    "    file_name = record[\"File Name\"]\n",
    "    file_type = record[\"File Type\"]\n",
    "    content = record[\"Content\"]\n",
    "    \n",
    "    # Detectar habilidades\n",
    "    skills = detect_skills_transformers(content)\n",
    "    \n",
    "    # Detectar nivel de inglés\n",
    "    english_level = detect_english_level_transformers(content)\n",
    "    \n",
    "    # Extraer edad y género\n",
    "    age, gender = extract_entities(content)\n",
    "    \n",
    "    # Guardar resultados\n",
    "    data_processed.append({\n",
    "        \"File Name\": file_name,\n",
    "        \"File Type\": file_type,\n",
    "        \"Skills\": \", \".join(skills),\n",
    "        \"English Level\": english_level,\n",
    "        \"Age\": age,\n",
    "        \"Gender\": gender,\n",
    "        \"Content\": content\n",
    "    })\n",
    "\n",
    "# Crear un DataFrame y guardar los resultados\n",
    "df_processed = pd.DataFrame(data_processed)\n",
    "df_processed.to_csv(\"dataset_procesado_transformers.csv\", index=False)\n",
    "\n",
    "print(\"Archivo 'dataset_procesado_transformers.csv' creado con éxito.\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
